{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cace664",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies and Bring in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d189308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fee3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[7]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf85736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[2:]].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd794a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['toxic'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67cd5aa",
   "metadata": {},
   "source": [
    "## 1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de893a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e34b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of words in the vocabulary.\n",
    "MAX_FEATURES = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens = MAX_FEATURES,\n",
    "                              output_sequence_length = 1800,\n",
    "                              output_mode = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75845700",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer(\"Hello world, How are you?\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeee4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCSHBAP - map, cache, shuffle, batch, prefetch from tensor_slices and list_files\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache() # Caches the data\n",
    "dataset = dataset.shuffle(160000) # Shuffles the data, 160000 is buffer size.\n",
    "dataset = dataset.batch(16) # Each batch will be represented as a series of 16 samples.\n",
    "dataset = dataset.prefetch(8) # Helps prevents bottlenecks(conjusted traffic flow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb01688",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e654d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(dataset)*.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b00ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7)) # 70% of the length of the dataset(batches) taken in training part.\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2)) # Skip the 70% of the dataset and then take 20% from remaining dataset.\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1)) # Same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f753dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.next() # Run it again and again, you will se it changing, as it moves from one batch to other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f89ceb",
   "metadata": {},
   "source": [
    "## 2. Create Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633abf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Create the embedding layer.\n",
    "model.add(Embedding(MAX_FEATURES + 1, 32))\n",
    "# Create LSTM with 32 different units with activation function as tanh\n",
    "model.add(Bidirectional(LSTM(32, activation = 'tanh')))\n",
    "# Feature extractor fully connected layers.\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "# Final layer. Maps to the different outputs inside of our neural network\n",
    "model.add(Dense(6, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebe27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'BinaryCrossentropy', optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, epochs = 15, validation_data = val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55826d3a",
   "metadata": {},
   "source": [
    "## 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck! I am going to hurt you' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb0380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(input_text, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd67a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(input_text, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c146687",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53572a94",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04776889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e6276",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    # Unpack the batch.\n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction.\n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions.\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbc9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()},Recall: {re.result().numpy()},Accuracy: {acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb70e12",
   "metadata": {},
   "source": [
    "## 5. Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04364de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('htccolab.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30aaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('htccolab.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer('Hey I freaken hate you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8bec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(input_str, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ddcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx] > 0.5)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513dfef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn = score_comment, \n",
    "                         inputs = gr.inputs.Textbox(lines = 2, placeholder = 'Comment to score'),\n",
    "                         outputs = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
